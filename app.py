# app.pyï¼šFlask åç«¯æœåŠ¡ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
#æ›´æ–°pythonä¸º3.9ä»¥ä¸Šï¼šbrew install python@3.11
# å®‰è£…ä¾èµ–ï¼ˆå¦‚æœæœªå®‰è£…ï¼‰ï¼špip install flask transformers beautifulsoup4 requests

import os
import sys
import json
from flask import Flask, request, jsonify, render_template
import requests
from bs4 import BeautifulSoup

# åŠ è½½.envæ–‡ä»¶
try:
    from dotenv import load_dotenv
    load_dotenv()
    print("âœ… å·²åŠ è½½ .env æ–‡ä»¶")
except ImportError:
    print("âš ï¸ python-dotenv æœªå®‰è£…ï¼Œå°†å°è¯•ä»ç³»ç»Ÿç¯å¢ƒå˜é‡è¯»å–é…ç½®")

app = Flask(__name__)

# ä¸ºä¸­å›½ç”¨æˆ·é…ç½®é•œåƒæº
def setup_china_mirrors():
    """é…ç½®ä¸­å›½å‹å¥½çš„é•œåƒæº"""
    print("ğŸ‡¨ğŸ‡³ é…ç½®ä¸­å›½é•œåƒæº...")
    
    # è®¾ç½® Hugging Face é•œåƒ
    os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
    
    # è®¾ç½®ä»£ç†é€‰é¡¹ï¼ˆå¦‚æœéœ€è¦ï¼‰
    os.environ['HF_HUB_DISABLE_PROGRESS_BARS'] = '1'
    os.environ['HF_HUB_CACHE'] = './models_cache'
    
    # è®¾ç½®è¯·æ±‚è¶…æ—¶å’Œé‡è¯•
    os.environ['HF_HUB_TIMEOUT'] = '60'
    
    print("âœ… é•œåƒæºé…ç½®å®Œæˆ")

def load_model_with_fallback():
    """å¸¦æœ‰é™çº§æ–¹æ¡ˆçš„æ¨¡å‹åŠ è½½"""
    try:
        print("ğŸ”„ å°è¯•åŠ è½½ zero-shot æ¨¡å‹...")
        from transformers import pipeline
        
        # å°è¯•å¤šä¸ªæ¨¡å‹æº
        model_options = [
            "MoritzLaurer/mDeBERTa-v3-base-mnli-xnli",  # å®˜æ–¹æ¨¡å‹
            "MoritzLaurer/mDeBERTa-v3-base-mnli",        # åŸå§‹æ¨¡å‹  
            "microsoft/deberta-v3-base",                  # åŸºç¡€æ¨¡å‹
        ]
        
        for model_name in model_options:
            try:
                print(f"ğŸ“¥ å°è¯•ä¸‹è½½æ¨¡å‹: {model_name}")
                classifier = pipeline(
                    "zero-shot-classification", 
                    model=model_name,
                    device=-1,  # ä½¿ç”¨CPUï¼Œé¿å…GPUé—®é¢˜
                    trust_remote_code=True
                )
                print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹: {model_name}")
                return classifier, "model"
            except Exception as e:
                print(f"âŒ æ¨¡å‹ {model_name} åŠ è½½å¤±è´¥: {str(e)}")
                continue
        
        # æ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥ï¼Œè¿”å›None
        return None, "failed"
        
    except ImportError:
        print("âŒ transformers åº“æœªå®‰è£…")
        return None, "no_transformers"
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        return None, "failed"

def rule_based_analysis(text):
    """åŸºäºè§„åˆ™çš„æ„è¯†å½¢æ€åˆ†æï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
    print("ğŸ”§ ä½¿ç”¨è§„åˆ™åˆ†ææ–¹æ¡ˆ...")
    
    # æ‰©å±•çš„å…³é”®è¯åº“
    advanced_keywords = {
        "å¥³æƒå€¾å‘": {
            "positive": ["å¥³æƒ", "å¹³æƒ", "ç‹¬ç«‹", "è‡ªä¸»", "å¹³ç­‰", "è§£æ”¾", "è‡ªç”±é€‰æ‹©", "èŒåœºå¥³æ€§"],
            "negative": ["åå¯¹", "æ‰¹è¯„", "è´¨ç–‘"],
            "weight": 1.0
        },
        "ç”·æƒå€¾å‘": {
            "positive": ["ä¼ ç»Ÿå®¶åº­", "ç”·ä¸»å¤–å¥³ä¸»å†…", "é¢†å¯¼åŠ›", "é˜³åˆš", "å®¶åº­è´£ä»»", "ä¿æŠ¤"],
            "negative": ["åå¯¹ä¼ ç»Ÿ", "è´¨ç–‘"],
            "weight": 1.0
        },
        "åŒå¥³å€¾å‘": {
            "positive": ["æ‹œé‡‘å¥³", "ç»¿èŒ¶", "æƒ…ç»ªåŒ–", "å¤©ç”ŸåŠ£ç­‰", "æ™ºå•†ä¸è¡Œ", "åªä¼šèŠ±é’±"],
            "negative": ["æ”¯æŒå¥³æ€§", "å°Šé‡"],
            "weight": 1.2
        },
        "å·¦å€¾è¡¨è¾¾": {
            "positive": ["äººæ°‘", "å·¥äºº", "åèµ„æœ¬", "å…¬æœ‰åˆ¶", "é›†ä½“åˆ©ç›Š", "ç¤¾ä¼šä¸»ä¹‰", "å…±äº§"],
            "negative": ["ç§æœ‰", "èµ„æœ¬ä¸»ä¹‰"],
            "weight": 1.0
        },
        "å³å€¾è¡¨è¾¾": {
            "positive": ["è‡ªç”±å¸‚åœº", "ç§æœ‰åˆ¶", "ä¸ªäººä¸»ä¹‰", "å‡ç¨", "å°æ”¿åºœ", "ä¼ä¸šå®¶"],
            "negative": ["å›½æœ‰", "è®¡åˆ’ç»æµ"],
            "weight": 1.0
        },
        "æƒ…ç»ªç¨³å®šæ€§": {
            "positive": ["å†·é™", "ç†æ€§", "å®¢è§‚", "åˆ†æ", "æ€è€ƒ"],
            "negative": ["æš´èº", "éª‚äºº", "æ„¤æ€’", "å†²åŠ¨", "æƒ…ç»ªåŒ–"],
            "weight": 0.8
        }
    }
    
    results = {}
    text_lower = text.lower()
    
    for label, config in advanced_keywords.items():
        # è®¡ç®—æ­£é¢è¯æ±‡å¾—åˆ†
        positive_score = sum(1 for word in config["positive"] if word in text_lower)
        # è®¡ç®—è´Ÿé¢è¯æ±‡å¾—åˆ†
        negative_score = sum(1 for word in config["negative"] if word in text_lower)
        
        # æ‰¾åˆ°åŒ¹é…çš„å…³é”®è¯
        found_keywords = []
        for word in config["positive"] + config["negative"]:
            if word in text_lower:
                found_keywords.append(word)
        
        # è®¡ç®—æœ€ç»ˆå¾—åˆ†
        base_score = (positive_score - negative_score * 0.5) * config["weight"]
        # å½’ä¸€åŒ–åˆ°0-100
        final_score = max(0, min(95, base_score * 15 + len(text_lower) * 0.01))
        
        results[label] = {
            "score": round(final_score, 2),
            "keywords": found_keywords[:5]  # æœ€å¤šæ˜¾ç¤º5ä¸ªå…³é”®è¯
        }
    
    return results

# åˆå§‹åŒ–é˜¶æ®µ
setup_china_mirrors()
classifier, model_status = load_model_with_fallback()

# ğŸ¯ ä¼˜åŒ–åçš„æ ‡ç­¾å®šä¹‰ - ä½¿ç”¨è¯¦ç»†æè¿°å‡å°‘æ­§ä¹‰
DETAILED_LABELS = {
    "å¥³æƒå€¾å‘": "æ”¯æŒå¥³æ€§æƒåˆ©ã€æ€§åˆ«å¹³ç­‰ã€å¥³æ€§ç‹¬ç«‹è‡ªä¸»å’Œåå¯¹æ€§åˆ«æ­§è§†çš„è§‚ç‚¹",
    "ç”·æƒå€¾å‘": "å¼ºè°ƒä¼ ç»Ÿæ€§åˆ«è§’è‰²ã€ç”·æ€§ä¸»å¯¼åœ°ä½ã€ä¼ ç»Ÿå®¶åº­åˆ†å·¥çš„è§‚ç‚¹", 
    "åŒå¥³å€¾å‘": "è´¬ä½ã€æ­§è§†ã€åè§ã€ä»‡è§†æˆ–ç”¨åˆ»æ¿å°è±¡æ”»å‡»å¥³æ€§çš„è§‚ç‚¹",
    "å·¦å€¾è¡¨è¾¾": "æ”¯æŒé›†ä½“ä¸»ä¹‰ã€ç¤¾ä¼šä¸»ä¹‰ã€åå¯¹èµ„æœ¬ä¸»ä¹‰æˆ–å¼ºè°ƒé˜¶çº§æ–—äº‰çš„è§‚ç‚¹",
    "å³å€¾è¡¨è¾¾": "æ”¯æŒä¸ªäººä¸»ä¹‰ã€è‡ªç”±å¸‚åœºã€èµ„æœ¬ä¸»ä¹‰æˆ–å¼ºè°ƒä¸ªäººè´£ä»»çš„è§‚ç‚¹",
    "æƒ…ç»ªç¨³å®šæ€§": "è¡¨è¾¾å†·é™ç†æ€§æ€è€ƒè€Œéæƒ…ç»ªåŒ–ã€æ„¤æ€’æˆ–æ”»å‡»æ€§çš„ç¨‹åº¦"
}

# ç®€çŸ­æ ‡ç­¾ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
DISPLAY_LABELS = ["å¥³æƒå€¾å‘", "ç”·æƒå€¾å‘", "åŒå¥³å€¾å‘", "å·¦å€¾è¡¨è¾¾", "å³å€¾è¡¨è¾¾", "æƒ…ç»ªç¨³å®šæ€§"]

# è¯¦ç»†æ ‡ç­¾ï¼ˆä¼ ç»™AIæ¨¡å‹ï¼‰
AI_LABELS = list(DETAILED_LABELS.values())

# ChatGPT é…ç½® - ä»ç¯å¢ƒå˜é‡è¯»å–
CHATGPT_API_BASE = os.getenv("CHATGPT_API_BASE", "https://apidekey.xyz")
CHATGPT_API_KEY = os.getenv("CHATGPT_API_KEY")
CHATGPT_MODEL = os.getenv("CHATGPT_MODEL", "gpt-4o")

MAX_TEXT_LENGTH = 2000

def chatgpt_analysis(text):
    """ä½¿ç”¨ChatGPTè¿›è¡Œæ„è¯†å½¢æ€åˆ†æ"""
    try:
        # æ£€æŸ¥APIå¯†é’¥æ˜¯å¦é…ç½®
        if not CHATGPT_API_KEY:
            print("âš ï¸ ChatGPT APIå¯†é’¥æœªé…ç½®ï¼Œè·³è¿‡ChatGPTåˆ†æ")
            return None
        
        print("ğŸš€ ä½¿ç”¨ChatGPTåˆ†æ...")
        
        # æ„å»ºä¸“é—¨çš„prompt
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸­æ–‡æ„è¯†å½¢æ€åˆ†æå¸ˆã€‚è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æ„è¯†å½¢æ€å€¾å‘ï¼Œå¹¶æŒ‰ç…§ä»¥ä¸‹6ä¸ªç»´åº¦è¯„åˆ†ï¼ˆ0-100åˆ†ï¼‰ï¼š

1. å¥³æƒå€¾å‘ï¼šæ”¯æŒå¥³æ€§æƒåˆ©ã€æ€§åˆ«å¹³ç­‰ã€å¥³æ€§ç‹¬ç«‹è‡ªä¸»å’Œåå¯¹æ€§åˆ«æ­§è§†çš„ç¨‹åº¦
2. ç”·æƒå€¾å‘ï¼šå¼ºè°ƒä¼ ç»Ÿæ€§åˆ«è§’è‰²ã€ç”·æ€§ä¸»å¯¼åœ°ä½ã€ä¼ ç»Ÿå®¶åº­åˆ†å·¥çš„ç¨‹åº¦  
3. åŒå¥³å€¾å‘ï¼šè´¬ä½ã€æ­§è§†ã€åè§ã€ä»‡è§†æˆ–ç”¨åˆ»æ¿å°è±¡æ”»å‡»å¥³æ€§çš„ç¨‹åº¦
4. å·¦å€¾è¡¨è¾¾ï¼šæ”¯æŒé›†ä½“ä¸»ä¹‰ã€ç¤¾ä¼šä¸»ä¹‰ã€åå¯¹èµ„æœ¬ä¸»ä¹‰æˆ–å¼ºè°ƒé˜¶çº§æ–—äº‰çš„ç¨‹åº¦
5. å³å€¾è¡¨è¾¾ï¼šæ”¯æŒä¸ªäººä¸»ä¹‰ã€è‡ªç”±å¸‚åœºã€èµ„æœ¬ä¸»ä¹‰æˆ–å¼ºè°ƒä¸ªäººè´£ä»»çš„ç¨‹åº¦
6. æƒ…ç»ªç¨³å®šæ€§ï¼šè¡¨è¾¾å†·é™ç†æ€§æ€è€ƒè€Œéæƒ…ç»ªåŒ–ã€æ„¤æ€’æˆ–æ”»å‡»æ€§çš„ç¨‹åº¦

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ç»“æœï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–å†…å®¹ï¼š
{{
    "å¥³æƒå€¾å‘": {{"score": åˆ†æ•°(0-100), "keywords": ["å…³é”®è¯1", "å…³é”®è¯2"], "explanation": "ç®€çŸ­è§£é‡Š"}},
    "ç”·æƒå€¾å‘": {{"score": åˆ†æ•°(0-100), "keywords": ["å…³é”®è¯1", "å…³é”®è¯2"], "explanation": "ç®€çŸ­è§£é‡Š"}},
    "åŒå¥³å€¾å‘": {{"score": åˆ†æ•°(0-100), "keywords": ["å…³é”®è¯1", "å…³é”®è¯2"], "explanation": "ç®€çŸ­è§£é‡Š"}},
    "å·¦å€¾è¡¨è¾¾": {{"score": åˆ†æ•°(0-100), "keywords": ["å…³é”®è¯1", "å…³é”®è¯2"], "explanation": "ç®€çŸ­è§£é‡Š"}},
    "å³å€¾è¡¨è¾¾": {{"score": åˆ†æ•°(0-100), "keywords": ["å…³é”®è¯1", "å…³é”®è¯2"], "explanation": "ç®€çŸ­è§£é‡Š"}},
    "æƒ…ç»ªç¨³å®šæ€§": {{"score": åˆ†æ•°(0-100), "keywords": ["å…³é”®è¯1", "å…³é”®è¯2"], "explanation": "ç®€çŸ­è§£é‡Š"}}
}}

åˆ†ææ–‡æœ¬ï¼š{text}"""

        # è°ƒç”¨OpenAI API
        headers = {
            "Authorization": f"Bearer {CHATGPT_API_KEY}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": CHATGPT_MODEL,
            "messages": [
                {
                    "role": "user", 
                    "content": prompt
                }
            ],
            "temperature": 0.1,  # é™ä½éšæœºæ€§ï¼Œç¡®ä¿ç»“æœä¸€è‡´æ€§
            "max_tokens": 1000
        }
        
        # å‘é€è¯·æ±‚
        response = requests.post(
            f"{CHATGPT_API_BASE}/v1/chat/completions",
            headers=headers,
            json=data,
            timeout=30
        )
        
        if response.status_code != 200:
            print(f"âŒ ChatGPT APIè¯·æ±‚å¤±è´¥: {response.status_code}")
            print(f"   å“åº”å†…å®¹: {response.text}")
            return None
        
        result = response.json()
        
        # æå–å›å¤å†…å®¹
        if 'choices' not in result or len(result['choices']) == 0:
            print("âŒ ChatGPTè¿”å›æ ¼å¼é”™è¯¯")
            return None
        
        content = result['choices'][0]['message']['content'].strip()
        print(f"ğŸ¤– ChatGPTåŸå§‹å›å¤: {content[:200]}...")
        
        # å°è¯•è§£æJSON
        try:
            # æ¸…ç†å¯èƒ½çš„markdownæ ¼å¼
            if content.startswith('```json'):
                content = content[7:]
            if content.endswith('```'):
                content = content[:-3]
            content = content.strip()
            
            analysis_result = json.loads(content)
            
            # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
            formatted_result = {}
            for dimension in DISPLAY_LABELS:
                if dimension in analysis_result:
                    formatted_result[dimension] = {
                        "score": float(analysis_result[dimension].get("score", 0)),
                        "method": "ChatGPTåˆ†æ",
                        "keywords": analysis_result[dimension].get("keywords", []),
                        "explanation": analysis_result[dimension].get("explanation", "")
                    }
                else:
                    # å¦‚æœæŸä¸ªç»´åº¦ç¼ºå¤±ï¼Œç»™é»˜è®¤å€¼
                    formatted_result[dimension] = {
                        "score": 0.0,
                        "method": "ChatGPTåˆ†æ",
                        "keywords": [],
                        "explanation": "åˆ†æç»“æœç¼ºå¤±"
                    }
            
            print("âœ… ChatGPTåˆ†æå®Œæˆ")
            return formatted_result
            
        except json.JSONDecodeError as e:
            print(f"âŒ ChatGPTè¿”å›JSONè§£æå¤±è´¥: {str(e)}")
            print(f"   åŸå§‹å†…å®¹: {content}")
            return None
            
    except requests.exceptions.Timeout:
        print("âŒ ChatGPTè¯·æ±‚è¶…æ—¶")
        return None
    except requests.exceptions.ConnectionError:
        print("âŒ ChatGPTè¿æ¥å¤±è´¥")
        return None
    except Exception as e:
        print(f"âŒ ChatGPTåˆ†æå¤±è´¥: {str(e)}")
        return None

def extract_text_from_url(url):
    """ä»URLæå–æ–‡æœ¬å†…å®¹ï¼Œæ”¯æŒå¤šç§ç½‘ç«™ç±»å‹"""
    
    # æ£€æŸ¥ä¸æ”¯æŒçš„ç½‘ç«™ç±»å‹
    unsupported_sites = {
        "weibo.com": "å¾®åš",
        "xiaohongshu.com": "å°çº¢ä¹¦", 
        "xhs.life": "å°çº¢ä¹¦",
        "douyin.com": "æŠ–éŸ³",
        "kuaishou.com": "å¿«æ‰‹",
        "bilibili.com": "Bç«™"
    }
    
    for site, name in unsupported_sites.items():
        if site in url:
            return f"[æš‚ä¸æ”¯æŒ{name}é“¾æ¥ï¼Œè¯·æ‰‹åŠ¨å¤åˆ¶æ–‡æœ¬å†…å®¹è¿›è¡Œåˆ†æ]"
    
    try:
        print(f"ğŸ”— å¼€å§‹æŠ“å–é“¾æ¥: {url}")
        
        # ä¼˜åŒ–è¯·æ±‚å¤´ï¼Œæ¨¡æ‹ŸçœŸå®æµè§ˆå™¨
        headers = {
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
            "Accept-Encoding": "gzip, deflate",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1",
        }
        
        resp = requests.get(url, headers=headers, timeout=15, allow_redirects=True)
        
        if resp.status_code != 200:
            return f"[ç½‘é¡µè®¿é—®å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{resp.status_code}ã€‚å¯èƒ½éœ€è¦ç™»å½•æˆ–è¯¥é¡µé¢ä¸å­˜åœ¨]"
        
        # æ”¹è¿›ç¼–ç æ£€æµ‹
        if resp.encoding == 'ISO-8859-1':
            resp.encoding = resp.apparent_encoding
        
        soup = BeautifulSoup(resp.text, "html.parser")
        
        # ç§»é™¤scriptå’Œstyleæ ‡ç­¾
        for script in soup(["script", "style", "nav", "header", "footer", "aside"]):
            script.decompose()
        
        # å¤šç§å†…å®¹æå–ç­–ç•¥
        content_parts = []
        
        # 1. å°è¯•æå–æ–‡ç« ä¸»ä½“ï¼ˆå¸¸è§çš„æ–‡ç« å®¹å™¨ï¼‰
        article_selectors = [
            "article", ".article", "#article",
            ".content", "#content", ".post-content",
            ".entry-content", ".article-content", 
            ".post-body", ".content-body",
            "[class*='content']", "[id*='content']"
        ]
        
        article_found = False
        for selector in article_selectors:
            article = soup.select_one(selector)
            if article:
                # æå–æ®µè½å’Œæ ‡é¢˜
                for element in article.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'div']):
                    text = element.get_text().strip()
                    if len(text) > 15:  # è¿‡æ»¤å¤ªçŸ­çš„æ–‡æœ¬
                        content_parts.append(text)
                article_found = True
                break
        
        # 2. å¦‚æœæ²¡æ‰¾åˆ°æ–‡ç« å®¹å™¨ï¼Œä½¿ç”¨é€šç”¨ç­–ç•¥
        if not article_found:
            # æå–æ‰€æœ‰æœ‰æ„ä¹‰çš„æ–‡æœ¬å…ƒç´ 
            for element in soup.find_all(['p', 'div', 'span', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6']):
                text = element.get_text().strip()
                # è¿‡æ»¤æ¡ä»¶ï¼šé•¿åº¦ > 15ï¼Œä¸æ˜¯çº¯æ•°å­—ï¼Œä¸æ˜¯å¸¸è§çš„æ— ç”¨æ–‡æœ¬
                if (len(text) > 15 and 
                    not text.isdigit() and 
                    not any(skip in text.lower() for skip in ['cookie', 'privacy', 'éšç§', 'ç‰ˆæƒ', 'copyright', 'ç™»å½•', 'æ³¨å†Œ'])):
                    content_parts.append(text)
        
        # 3. å»é‡å’Œæ’åº
        content_parts = list(dict.fromkeys(content_parts))  # å»é‡ä½†ä¿æŒé¡ºåº
        
        # 4. ç»„åˆæ–‡æœ¬
        combined = " ".join(content_parts)
        
        # 5. æ¸…ç†å’Œé™åˆ¶é•¿åº¦
        if combined:
            # åŸºæœ¬æ¸…ç†
            combined = " ".join(combined.split())  # æ¸…ç†å¤šä½™ç©ºç™½
            combined = combined.replace('\n', ' ').replace('\r', ' ')
            
            print(f"âœ… æŠ“å–æˆåŠŸï¼Œæ–‡æœ¬é•¿åº¦: {len(combined)} å­—ç¬¦")
            return combined[:MAX_TEXT_LENGTH] if len(combined) > MAX_TEXT_LENGTH else combined
        else:
            return "[ç½‘é¡µå†…å®¹ä¸ºç©ºæˆ–æ— æ³•æå–æ–‡æœ¬ã€‚å¯èƒ½æ˜¯åŠ¨æ€åŠ è½½å†…å®¹ï¼Œå»ºè®®æ‰‹åŠ¨å¤åˆ¶æ–‡æœ¬]"
            
    except requests.exceptions.Timeout:
        return "[ç½‘é¡µè®¿é—®è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•]"
    except requests.exceptions.ConnectionError:
        return "[ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘å€æ˜¯å¦æ­£ç¡®]"
    except Exception as e:
        print(f"âŒ æŠ“å–å¤±è´¥: {str(e)}")
        return f"[ç½‘é¡µæŠ“å–å¤±è´¥ï¼š{str(e)}ã€‚å»ºè®®æ‰‹åŠ¨å¤åˆ¶æ–‡æœ¬å†…å®¹]"

def analyze_text(text):
    """ç»Ÿä¸€çš„æ–‡æœ¬åˆ†ææ¥å£ - å®ç°é™çº§ç­–ç•¥ï¼šChatGPT â†’ æœ¬åœ°AI â†’ è§„åˆ™åˆ†æ"""
    if len(text) > MAX_TEXT_LENGTH:
        return {"error": "è¾“å…¥æ–‡æœ¬è¶…å‡ºé•¿åº¦é™åˆ¶ï¼ˆ2000 å­—ç¬¦ï¼‰"}
    
    if text.startswith("[") and text.endswith("]"):
        return {"error": text}
    
    # æ–¹æ¡ˆ1: å°è¯•ChatGPTåˆ†æ
    try:
        chatgpt_result = chatgpt_analysis(text)
        if chatgpt_result is not None:
            return chatgpt_result
        else:
            print("âš ï¸ ChatGPTåˆ†æå¤±è´¥ï¼Œé™çº§åˆ°æœ¬åœ°AIæ¨¡å‹...")
    except Exception as e:
        print(f"âš ï¸ ChatGPTåˆ†æå¼‚å¸¸: {str(e)}ï¼Œé™çº§åˆ°æœ¬åœ°AIæ¨¡å‹...")
    
    # æ–¹æ¡ˆ2: å°è¯•æœ¬åœ°AIæ¨¡å‹åˆ†æ
    try:
        if classifier and model_status == "model":
            print("ğŸ¤– ä½¿ç”¨æœ¬åœ°AIæ¨¡å‹åˆ†æ...")
            result = classifier(text, AI_LABELS, multi_label=True)
            response = {}
            
            # å°†AIç»“æœæ˜ å°„å›æ˜¾ç¤ºæ ‡ç­¾
            for i, (detailed_label, score) in enumerate(zip(result['labels'], result['scores'])):
                try:
                    label_index = AI_LABELS.index(detailed_label)
                    display_label = DISPLAY_LABELS[label_index]
                except ValueError:
                    # å¦‚æœæ‰¾ä¸åˆ°åŒ¹é…é¡¹ï¼Œå°è¯•ç›´æ¥ä½¿ç”¨ç®€çŸ­æ ‡ç­¾æ˜ å°„
                    label_mapping = {
                        "æ”¯æŒå¥³æ€§æƒåˆ©ã€æ€§åˆ«å¹³ç­‰ã€å¥³æ€§ç‹¬ç«‹è‡ªä¸»å’Œåå¯¹æ€§åˆ«æ­§è§†çš„è§‚ç‚¹": "å¥³æƒå€¾å‘",
                        "å¼ºè°ƒä¼ ç»Ÿæ€§åˆ«è§’è‰²ã€ç”·æ€§ä¸»å¯¼åœ°ä½ã€ä¼ ç»Ÿå®¶åº­åˆ†å·¥çš„è§‚ç‚¹": "ç”·æƒå€¾å‘",
                        "è´¬ä½ã€æ­§è§†ã€åè§ã€ä»‡è§†æˆ–ç”¨åˆ»æ¿å°è±¡æ”»å‡»å¥³æ€§çš„è§‚ç‚¹": "åŒå¥³å€¾å‘",
                        "æ”¯æŒé›†ä½“ä¸»ä¹‰ã€ç¤¾ä¼šä¸»ä¹‰ã€åå¯¹èµ„æœ¬ä¸»ä¹‰æˆ–å¼ºè°ƒé˜¶çº§æ–—äº‰çš„è§‚ç‚¹": "å·¦å€¾è¡¨è¾¾",
                        "æ”¯æŒä¸ªäººä¸»ä¹‰ã€è‡ªç”±å¸‚åœºã€èµ„æœ¬ä¸»ä¹‰æˆ–å¼ºè°ƒä¸ªäººè´£ä»»çš„è§‚ç‚¹": "å³å€¾è¡¨è¾¾",
                        "è¡¨è¾¾å†·é™ç†æ€§æ€è€ƒè€Œéæƒ…ç»ªåŒ–ã€æ„¤æ€’æˆ–æ”»å‡»æ€§çš„ç¨‹åº¦": "æƒ…ç»ªç¨³å®šæ€§"
                    }
                    display_label = label_mapping.get(detailed_label, f"æœªçŸ¥æ ‡ç­¾_{i}")
                
                response[display_label] = {
                    "score": round(score * 100, 2),
                    "method": "æœ¬åœ°AIæ¨¡å‹",
                    "keywords": [],  # AIæ¨¡å‹ä¸éœ€è¦æ˜¾ç¤ºå…³é”®è¯
                    "description": detailed_label  # å¯é€‰ï¼šæ˜¾ç¤ºè¯¦ç»†æè¿°
                }
            return response
        else:
            print("âš ï¸ æœ¬åœ°AIæ¨¡å‹ä¸å¯ç”¨ï¼Œé™çº§åˆ°è§„åˆ™åˆ†æ...")
    except Exception as e:
        print(f"âš ï¸ æœ¬åœ°AIæ¨¡å‹åˆ†æå¤±è´¥: {str(e)}ï¼Œé™çº§åˆ°è§„åˆ™åˆ†æ...")
    
    # æ–¹æ¡ˆ3: è§„åˆ™åˆ†æï¼ˆæœ€ç»ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
    try:
        print("ğŸ“ ä½¿ç”¨è§„åˆ™åˆ†æï¼ˆæœ€ç»ˆæ–¹æ¡ˆï¼‰...")
        result = rule_based_analysis(text)
        for label in result:
            result[label]["method"] = "è§„åˆ™åˆ†æ"
        return result
    except Exception as e:
        print(f"âŒ æ‰€æœ‰åˆ†ææ–¹æ¡ˆéƒ½å¤±è´¥: {str(e)}")
        # è¿”å›é»˜è®¤ç»“æœ
        return {
            label: {
                "score": 0.0,
                "method": "åˆ†æå¤±è´¥",
                "keywords": [],
                "explanation": f"åˆ†æå¤±è´¥: {str(e)}"
            } for label in DISPLAY_LABELS
        }

@app.route("/")
def index():
    return render_template("index.html")

@app.route("/extract", methods=["POST"])
def extract():
    """åªæå–å†…å®¹ï¼Œä¸åˆ†æ"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "è¯·æ±‚æ•°æ®ä¸ºç©º"})
            
        input_url = data.get("url", "").strip()
        
        if not input_url:
            return jsonify({"error": "è¯·è¾“å…¥è¦æå–çš„URL"})
        
        text = extract_text_from_url(input_url)
        
        if text.startswith("[") and text.endswith("]"):
            return jsonify({"error": text})
        
        return jsonify({
            "success": True,
            "text": text,
            "length": len(text)
        })
        
    except Exception as e:
        print(f"âŒ æå–è¯·æ±‚å¤±è´¥: {str(e)}")
        return jsonify({"error": f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}"})

@app.route("/analyze", methods=["POST"])
def analyze():
    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "è¯·æ±‚æ•°æ®ä¸ºç©º"})
            
        input_text = data.get("text", "").strip()
        input_url = data.get("url", "").strip()
        
        # ä¼˜å…ˆä½¿ç”¨URLï¼Œå…¶æ¬¡ä½¿ç”¨æ–‡æœ¬
        if input_url:
            text = extract_text_from_url(input_url)
        elif input_text:
            if input_text.startswith("http"):
                text = extract_text_from_url(input_text)
            else:
                text = input_text
        else:
            return jsonify({"error": "è¯·è¾“å…¥è¦åˆ†æçš„æ–‡æœ¬æˆ–URL"})
        
        print(f"ğŸ“ åˆ†ææ–‡æœ¬: {text[:100]}..." if len(text) > 100 else f"ğŸ“ åˆ†ææ–‡æœ¬: {text}")
        result = analyze_text(text)
        print(f"âœ… åˆ†æç»“æœ: {result}")
        return jsonify(result)
        
    except Exception as e:
        print(f"âŒ åˆ†æè¯·æ±‚å¤±è´¥: {str(e)}")
        return jsonify({"error": f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}"})

@app.route("/health")
def health():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹ - å‰ç«¯é¡µé¢åŠ è½½æ—¶è°ƒç”¨"""
    return jsonify({
        "status": "ok",
        "model_loaded": classifier is not None,
        "analysis_engine": "AIæ¨¡å‹" if classifier else "è§„åˆ™åˆ†æ"
    })

@app.route("/status")
def status():
    """ç³»ç»ŸçŠ¶æ€æ£€æŸ¥"""
    return jsonify({
        "model_status": model_status,
        "analysis_method": "AIæ¨¡å‹" if classifier else "è§„åˆ™åˆ†æ",
        "china_optimized": True,
        "mirror_endpoint": os.environ.get('HF_ENDPOINT', 'default')
    })

def find_available_port(start_port=5000, max_attempts=10):
    """æŸ¥æ‰¾å¯ç”¨ç«¯å£"""
    import socket
    
    for port in range(start_port, start_port + max_attempts):
        try:
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                s.bind(('localhost', port))
                return port
        except OSError:
            continue
    return None

if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨æ„è¯†å½¢æ€åˆ†æå™¨...")
    print(f"ğŸ“Š æœ¬åœ°AIæ¨¡å‹: {'å·²åŠ è½½' if classifier else 'æœªåŠ è½½'}")
    print(f"ğŸ¤– ChatGPTåˆ†æ: {'å·²é…ç½®' if CHATGPT_API_KEY else 'æœªé…ç½®'}")
    
    # æ˜¾ç¤ºåˆ†ææ–¹æ³•ä¼˜å…ˆçº§
    methods = []
    if CHATGPT_API_KEY:
        methods.append("ChatGPT")
    if classifier:
        methods.append("æœ¬åœ°AI")
    methods.append("è§„åˆ™åˆ†æ")
    print(f"ğŸ“‹ åˆ†ææ–¹æ³•ä¼˜å…ˆçº§: {' â†’ '.join(methods)}")
    
    # æŸ¥æ‰¾å¯ç”¨ç«¯å£
    available_port = find_available_port(5000)
    
    if available_port is None:
        print("âŒ æ— æ³•æ‰¾åˆ°å¯ç”¨ç«¯å£ (5000-5009)")
        print("ğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
        print("   1. å…³é—­å…¶ä»–å ç”¨ç«¯å£çš„ç¨‹åº")
        print("   2. macOSç”¨æˆ·: ç³»ç»Ÿåå¥½è®¾ç½® -> é€šç”¨ -> éš”ç©ºæŠ•é€ä¸æ¥åŠ› -> å…³é—­'éš”ç©ºæ’­æ”¾æ¥æ”¶å™¨'")
        exit(1)
    
    if available_port != 5000:
        print(f"âš ï¸ ç«¯å£5000è¢«å ç”¨ï¼Œä½¿ç”¨ç«¯å£ {available_port}")
        print("ğŸ’¡ å¦‚æœæ˜¯macOSï¼Œå¯èƒ½æ˜¯AirPlayå ç”¨äº†5000ç«¯å£")
    
    print(f"ğŸŒ è®¿é—®: http://localhost:{available_port}")
    print(f"ğŸ” çŠ¶æ€æ£€æŸ¥: http://localhost:{available_port}/status")
    
    try:
        app.run(debug=True, host='0.0.0.0', port=available_port)
    except KeyboardInterrupt:
        print("\nğŸ‘‹ åº”ç”¨å·²åœæ­¢")
    except Exception as e:
        print(f"âŒ å¯åŠ¨å¤±è´¥: {str(e)}")
        print("ğŸ’¡ è¯·æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨æˆ–å°è¯•ä»¥ç®¡ç†å‘˜æƒé™è¿è¡Œ")
